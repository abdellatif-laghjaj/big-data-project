{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from hdfs import InsecureClient\n",
    "import cv2\n",
    "import tempfile\n",
    "import uuid\n",
    "import numpy as np\n",
    "import io, os, subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import wiener"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Spark Session\n",
    "### Initialize Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ImageProcessing\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List Videos in HDFS Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_in_hdfs(directory):\n",
    "    proc = subprocess.Popen(['hdfs', 'dfs', '-ls', directory], stdout=subprocess.PIPE)\n",
    "    output = proc.communicate()[0].decode('utf-8')  # Decode bytes to string\n",
    "    files = []\n",
    "    for line in output.split('\\n'):\n",
    "        parts = line.split()\n",
    "        print(parts)\n",
    "\n",
    "        if len(parts) > 7:\n",
    "            files.append(parts[7])\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_files = list_files_in_hdfs('/student_videos')\n",
    "print(video_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Video from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_videos_from_hdfs(hdfs_files, local_dir):\n",
    "    \"\"\"\n",
    "    Download video files from HDFS to the local directory, only if they don't already exist.\n",
    "    :param hdfs_files: List of HDFS file paths.\n",
    "    :param local_dir: Local directory to store the videos.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(local_dir):\n",
    "        os.makedirs(local_dir)\n",
    "\n",
    "    for hdfs_file in hdfs_files:\n",
    "        local_file = os.path.join(local_dir, os.path.basename(hdfs_file))\n",
    "        if not os.path.exists(local_file):\n",
    "            print(f\"Downloading {hdfs_file} to {local_file}\")\n",
    "            subprocess.run(['hdfs', 'dfs', '-get', hdfs_file, local_file], check=True)\n",
    "        else:\n",
    "            print(f\"File {local_file} already exists. Skipping download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Frames from Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, num_frames):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    step = total_frames // num_frames\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i * step)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_videos_from_hdfs(video_files, 'videos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read content in the videos directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_videos_from_dir(directory):\n",
    "    videos = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".mp4\"):\n",
    "            videos.append(os.path.join(directory, file))\n",
    "    return videos\n",
    "\n",
    "videos = read_videos_from_dir('videos')\n",
    "print(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(images, titles=None, rows=2, cols=3, figsize=(15, 10)):\n",
    "    \"\"\"Display multiple images in a grid.\"\"\"\n",
    "    if titles is None:\n",
    "        titles = [''] * len(images)\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        if i < len(images):\n",
    "            ax.imshow(images[i])\n",
    "            ax.set_title(titles[i])\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = 6\n",
    "frames = extract_frames(videos[3], num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the frames\n",
    "display_images(frames, titles=[f'Frame {i + 1}' for i in range(num_frames)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application des techniques de traitement d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the frames to grayscale\n",
    "def convert_to_grayscale(image):\n",
    "    \"\"\"Convert an image to grayscale.\"\"\"\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Égalisation de l'histogramme\n",
    "def equalize_histogram(image):\n",
    "    \"\"\"Equalize the histogram of a grayscale image.\"\"\"\n",
    "    # Séparer les canaux de couleur\n",
    "    canal_b, canal_g, canal_r = cv2.split(image)\n",
    "\n",
    "    # Appliquer l'égalisation d'histogramme à chaque canal de couleur\n",
    "    canal_b_eq = cv2.equalizeHist(canal_b)\n",
    "    canal_g_eq = cv2.equalizeHist(canal_g)\n",
    "    canal_r_eq = cv2.equalizeHist(canal_r)\n",
    "\n",
    "    # Fusionner les canaux de couleur égalisés\n",
    "    image_eq = cv2.merge((canal_b_eq, canal_g_eq, canal_r_eq))\n",
    "\n",
    "    return image_eq\n",
    "\n",
    "# Appliquer un filtre gaussien avec un noyau de taille 5x5\n",
    "def apply_gaussian_blur(image, ksize=5):\n",
    "    \"\"\"Apply a Gaussian blur to the image.\"\"\"\n",
    "    return cv2.GaussianBlur(image, (ksize, ksize), 0)\n",
    "\n",
    "# Apply laplacian filter\n",
    "def apply_laplacian(image):\n",
    "    # Split the image into its color channels\n",
    "    b, g, r = cv2.split(image)\n",
    "\n",
    "    # Apply Laplacian filter to each channel\n",
    "    b_lap = cv2.Laplacian(b, cv2.CV_64F)\n",
    "    g_lap = cv2.Laplacian(g, cv2.CV_64F)\n",
    "    r_lap = cv2.Laplacian(r, cv2.CV_64F)\n",
    "\n",
    "    # Convert back to uint8\n",
    "    b_lap = np.uint8(np.absolute(b_lap))\n",
    "    g_lap = np.uint8(np.absolute(g_lap))\n",
    "    r_lap = np.uint8(np.absolute(r_lap))\n",
    "\n",
    "    # Merge the sharpened channels\n",
    "    sharpened = cv2.merge((b_lap, g_lap, r_lap))\n",
    "\n",
    "    return sharpened\n",
    "\n",
    "# Apply Sobel filter\n",
    "def apply_sobel_filter(image):\n",
    "    # Split the image into its color channels\n",
    "    b, g, r = cv2.split(image)\n",
    "\n",
    "    # Apply Sobel filter to each channel\n",
    "    b_sobel_x = cv2.Sobel(b, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    b_sobel_y = cv2.Sobel(b, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    g_sobel_x = cv2.Sobel(g, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    g_sobel_y = cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    r_sobel_x = cv2.Sobel(r, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    r_sobel_y = cv2.Sobel(r, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "    # Convert back to uint8\n",
    "    b_sobel_x = np.uint8(np.absolute(b_sobel_x))\n",
    "    b_sobel_y = np.uint8(np.absolute(b_sobel_y))\n",
    "    g_sobel_x = np.uint8(np.absolute(g_sobel_x))\n",
    "    g_sobel_y = np.uint8(np.absolute(g_sobel_y))\n",
    "    r_sobel_x = np.uint8(np.absolute(r_sobel_x))\n",
    "    r_sobel_y = np.uint8(np.absolute(r_sobel_y))\n",
    "\n",
    "    # Merge the Sobel channels\n",
    "    sobel = cv2.merge((b_sobel_x, g_sobel_y, r_sobel_x))\n",
    "\n",
    "    return sobel\n",
    "\n",
    "# Sharpen the image\n",
    "def sharpen_image(image):\n",
    "    # Create the sharpening kernel \n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]) \n",
    "\n",
    "    # Sharpen the image \n",
    "    sharpened_image = cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "    return sharpened_image\n",
    "\n",
    "# Enhance RGB image quality\n",
    "def enhance_rgb_quality(image):\n",
    "    \"\"\"Enhance the quality of an RGB image using histogram equalization.\"\"\"\n",
    "    # Convert image to LAB color space\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "\n",
    "    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    lab_image[:, :, 0] = clahe.apply(lab_image[:, :, 0])\n",
    "\n",
    "    # Convert back to RGB color space\n",
    "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "    return enhanced_image\n",
    "\n",
    "# Remove blur effect from RGB image\n",
    "def remove_blur_effect(image):\n",
    "    # Split the image into its color channels\n",
    "    b, g, r = cv2.split(image)\n",
    "\n",
    "    # Apply Wiener deconvolution to each color channel to deblur\n",
    "    deblurred_b = wiener(b, (5, 5), 0.01)\n",
    "    deblurred_g = wiener(g, (5, 5), 0.01)\n",
    "    deblurred_r = wiener(r, (5, 5), 0.01)\n",
    "\n",
    "    # Convert the deblurred images back to uint8\n",
    "    deblurred_b = np.uint8(deblurred_b)\n",
    "    deblurred_g = np.uint8(deblurred_g)\n",
    "    deblurred_r = np.uint8(deblurred_r)\n",
    "\n",
    "    # Merge the deblurred color channels\n",
    "    deblurred = cv2.merge((deblurred_b, deblurred_g, deblurred_r))\n",
    "\n",
    "    return deblurred\n",
    "\n",
    "\n",
    "# Apply Mediane filter\n",
    "def apply_median_filter(image, ksize=5):\n",
    "    # Split the image into its color channels\n",
    "    b, g, r = cv2.split(image)\n",
    "\n",
    "    # Apply median blur to each color channel separately\n",
    "    blurred_b = cv2.medianBlur(b, ksize)\n",
    "    blurred_g = cv2.medianBlur(g, ksize)\n",
    "    blurred_r = cv2.medianBlur(r, ksize)\n",
    "\n",
    "    # Merge the blurred color channels\n",
    "    blurred = cv2.merge((blurred_b, blurred_g, blurred_r))\n",
    "\n",
    "    return blurred\n",
    "\n",
    "# Adjusts the brightness by adding 10 to each pixel value \n",
    "def adjust_brightness(image, brightness=10, contrast=1.0):\n",
    "    adjusted_image = cv2.addWeighted(image, contrast, np.zeros(image.shape, image.dtype), 0, brightness)\n",
    "    return adjusted_image  \n",
    "\n",
    "# Rotation\n",
    "def rotate_image(image, angle=90, scale=1.0):\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w / 2, h / 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    rotated_image = cv2.warpAffine(image, M, (w, h))\n",
    "    return rotated_image\n",
    "\n",
    "# Cropping\n",
    "def crop_image(image, x, y, w, h):\n",
    "    cropped_image = image[y:y+h, x:x+w]\n",
    "    return cropped_image\n",
    "\n",
    "# Resize\n",
    "def resize_image(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    resized_image = cv2.resize(image, dim, interpolation=inter)\n",
    "    return resized_image\n",
    "\n",
    "# Zooming\n",
    "def zoom_image(image, zoom_factor=1.5):\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w / 2, h / 2)\n",
    "    M = cv2.getRotationMatrix2D(center, 0, zoom_factor)\n",
    "    zoomed_image = cv2.warpAffine(image, M, (w, h))\n",
    "    return zoomed_image\n",
    "\n",
    "# Edge detection\n",
    "def detect_edges(image):\n",
    "    \"\"\"Detect edges in the input image using the Canny Edge Detector.\"\"\"\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Setting parameter values\n",
    "    t_lower = 50  # Lower Threshold\n",
    "    t_upper = 150  # Upper threshold\n",
    "\n",
    "    # Applying the Canny Edge filter\n",
    "    edge = cv2.Canny(gray_image, t_lower, t_upper)\n",
    "\n",
    "    return edge\n",
    "\n",
    "# Dilation\n",
    "def dilate_image(image, ksize=5):\n",
    "    kernel = np.ones((ksize, ksize), np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations=1)\n",
    "\n",
    "# Erosion\n",
    "def erode_image(image, ksize=5):\n",
    "    kernel = np.ones((ksize, ksize), np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations=1)\n",
    "\n",
    "# Opening\n",
    "def open_image(image, ksize=5):\n",
    "    kernel = np.ones((ksize, ksize), np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# Closing\n",
    "def close_image(image, ksize=5):\n",
    "    kernel = np.ones((ksize, ksize), np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Bilateral filter\n",
    "def apply_bilateral_filter(image, d=3, sigmaColor=15, sigmaSpace=15):\n",
    "    # Apply Bilateral Filter\n",
    "    return cv2.bilateralFilter(image, d, sigmaColor, sigmaSpace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the images in the HDFS directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_to_hdfs(image, target_dir, operation_type, filename_prefix='result'):\n",
    "    \"\"\"\n",
    "    Save the processed image to HDFS.\n",
    "\n",
    "    Parameters:\n",
    "    - image: The processed image (NumPy array).\n",
    "    - target_dir: The target directory in HDFS.\n",
    "    - operation_type: The type of operation applied to the image (e.g., rotation, cropping, enhancement).\n",
    "    - filename_prefix: Prefix for the saved filename (default is 'result').\n",
    "\n",
    "    Returns:\n",
    "    - saved_filename: The filename under which the image is saved.\n",
    "    \"\"\"\n",
    "    # HDFS Client\n",
    "    hdfs_client = InsecureClient('http://localhost:9870', user='hdfs')\n",
    "\n",
    "    # Check and create target directory if it doesn't exist\n",
    "    if not hdfs_client.content(target_dir, strict=False):\n",
    "        print(f\"Creating directory: {target_dir}\")\n",
    "        hdfs_client.makedirs(target_dir, permission=777)\n",
    "\n",
    "    # Define the filename based on the operation type\n",
    "    saved_filename = f'{filename_prefix}_{operation_type}_{uuid.uuid4()}.png'\n",
    "\n",
    "    # Save the image locally\n",
    "    local_path = os.path.join(tempfile.gettempdir(), saved_filename)\n",
    "    cv2.imwrite(local_path, image)\n",
    "\n",
    "    # Write the image to HDFS\n",
    "    with hdfs_client.write(f'{target_dir}/{saved_filename}', overwrite=True) as hdfs_file:\n",
    "        with open(local_path, 'rb') as local_file:\n",
    "            hdfs_file.write(local_file.read())\n",
    "\n",
    "    return saved_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized_img = equalize_histogram(frames[0])\n",
    "laplacian_sharpened = apply_laplacian(equalized_img)\n",
    "enhanced_img = enhance_rgb_quality(frames[0])\n",
    "adjusted_img = adjust_brightness(enhanced_img, brightness=10)\n",
    "sobel_img = apply_sobel_filter(frames[0])\n",
    "sharpened_image = sharpen_image(frames[0])\n",
    "rotated_img = rotate_image(frames[0], angle=45)\n",
    "cropped_img = crop_image(frames[0], 100, 100, 200, 200)\n",
    "resized_img = resize_image(frames[0], width=1800)\n",
    "zoomed_img = zoom_image(frames[0], zoom_factor=1.5)\n",
    "edges_img = detect_edges(frames[0])\n",
    "dilated_img = dilate_image(enhanced_img)\n",
    "eroded_img = erode_image(enhanced_img)\n",
    "opened_img = open_image(enhanced_img)\n",
    "closed_img = close_image(enhanced_img)\n",
    "bilateral_filtered_img = apply_bilateral_filter(frames[0])\n",
    "\n",
    "# Save the processed images to HDFS\n",
    "equalized_filename = save_image_to_hdfs(equalized_img, '/processed_images', 'equalized')\n",
    "laplacian_sharpened_filename = save_image_to_hdfs(laplacian_sharpened, '/processed_images', 'laplacian_sharpened')\n",
    "enhanced_filename = save_image_to_hdfs(enhanced_img, '/processed_images', 'enhanced')\n",
    "adjusted_filename = save_image_to_hdfs(adjusted_img, '/processed_images', 'adjusted')\n",
    "sobel_filename = save_image_to_hdfs(sobel_img, '/processed_images', 'sobel')\n",
    "sharpened_filename = save_image_to_hdfs(sharpened_image, '/processed_images', 'sharpened')\n",
    "rotated_filename = save_image_to_hdfs(rotated_img, '/processed_images', 'rotated')\n",
    "cropped_filename = save_image_to_hdfs(cropped_img, '/processed_images', 'cropped')\n",
    "resized_filename = save_image_to_hdfs(resized_img, '/processed_images', 'resized')\n",
    "\n",
    "# blur_removed_img = remove_blur_effect(enhanced_img)\n",
    "# median_blurred_img = apply_median_filter(frames[0], ksize=7)\n",
    "# Display the processed images\n",
    "display_images([frames[0], dilated_img, eroded_img, opened_img, closed_img, bilateral_filtered_img],\n",
    "                titles=['Original', 'Dilated', 'Eroded', 'Opened', 'Closed', 'Bilateral Filtered'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "akamenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
